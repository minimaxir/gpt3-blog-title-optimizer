{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT-3 Blog Title Optimizer Walkthrough\n",
    "\n",
    "Here's an annotated code walkthrough of how to leverage GPT-3 to build a title optimized.\n",
    "\n",
    "This notebook assumes you have a `OPENAI_API_KEY` specified in a `.env` file, e.g.\n",
    "\n",
    "```properties\n",
    "OPENAI_API_KEY=\"<FILL IN>\"\n",
    "FINETUNED_MODEL=\"<FILL IN>\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from math import exp\n",
    "\n",
    "import openai\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "assert os.getenv(\"OPENAI_API_KEY\"), \"No OPENAI_API_KEY defined in .env.\"\n",
    "assert os.getenv(\"FINETUNED_MODEL\"), \"No FINETUNED_MODEL defined in .env.\"\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Alternate Candidate Titles\n",
    "\n",
    "Set the base prompt to feed to GPT-3 such that you can impute whatever prompt is necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_prompt = \"Rewrite the following blog post title into six different titles but optimized for social media virality: {0}\\n\\n-\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ping OpenAI's Completion API, which returns JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-5ez1HIIrnqQrkLYKrj1jlLQbxkZ1T at 0x1199f39f0> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \"DALL-E 2 creates absurd AI-generated professional food photography \\n-A new level of absurdity: AI-generated professional food photography with DALL-E 2 \\n-DALL-E 2: The AI that creates absurdly realistic professional food photography \\n-How DALL-E 2 creates absurd AI-generated professional food photography \\n-DALL-E 2: Creating absurd AI-generated professional food photography \\n-The absurd AI-generated professional food photography of DALL-E 2\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1660449363,\n",
       "  \"id\": \"cmpl-5ez1HIIrnqQrkLYKrj1jlLQbxkZ1T\",\n",
       "  \"model\": \"text-davinci-002\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 104,\n",
       "    \"prompt_tokens\": 37,\n",
       "    \"total_tokens\": 141\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_input = \"Absurd AI-Generated Professional Food Photography with DALL-E 2\"\n",
    "\n",
    "r = openai.Completion.create(\n",
    "    model=\"text-davinci-002\",\n",
    "    prompt=base_prompt.format(title_input),\n",
    "    temperature=0,  # deterministic output; should set to 0.7 or 1 elsewise\n",
    "    max_tokens=256,  # fine for small titles but may need to bump\n",
    "    top_p=1,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0,\n",
    ")\n",
    "\n",
    "r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract and clean up the titles from the generated output. The biggest issue is that each title may or may not end with a space, so will have to a regular expression to account for that possibility instead of a straight `split(\"\\n-\")`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DALL-E 2 creates absurd AI-generated professional food photography',\n",
       " 'A new level of absurdity: AI-generated professional food photography with DALL-E 2',\n",
       " 'DALL-E 2: The AI that creates absurdly realistic professional food photography',\n",
       " 'How DALL-E 2 creates absurd AI-generated professional food photography',\n",
       " 'DALL-E 2: Creating absurd AI-generated professional food photography',\n",
       " 'The absurd AI-generated professional food photography of DALL-E 2']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_titles = re.split(r\" ?\\n-\", r[\"choices\"][0][\"text\"])\n",
    "gen_titles\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding if Generated Titles Are Good\n",
    "\n",
    "Now let's work with the finetuned GPT-3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetune_prompt = \"Title: {0} ->\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing out the original title first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-5ez1LNNuW81n8OnhQjaJQHGWpeQ37 at 0x116e1c090> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"length\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": {\n",
       "        \"text_offset\": [\n",
       "          73\n",
       "        ],\n",
       "        \"token_logprobs\": [\n",
       "          -0.34654787\n",
       "        ],\n",
       "        \"tokens\": [\n",
       "          \" bad\"\n",
       "        ],\n",
       "        \"top_logprobs\": [\n",
       "          {\n",
       "            \" bad\": -0.34654787\n",
       "          }\n",
       "        ]\n",
       "      },\n",
       "      \"text\": \" bad\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1660449367,\n",
       "  \"id\": \"cmpl-5ez1LNNuW81n8OnhQjaJQHGWpeQ37\",\n",
       "  \"model\": \"babbage:ft-personal-2022-08-14-02-01-33\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 1,\n",
       "    \"prompt_tokens\": 18,\n",
       "    \"total_tokens\": 19\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = openai.Completion.create(\n",
    "    model=os.getenv(\"FINETUNED_MODEL\"),\n",
    "    prompt=finetune_prompt.format(title_input),\n",
    "    temperature=0,  # must be 0\n",
    "    max_tokens=1,  # must be 1\n",
    "    logprobs=1,  # returns the probability\n",
    ")\n",
    "\n",
    "r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " bad\n",
      "0.7071249684048194\n"
     ]
    }
   ],
   "source": [
    "title_class = r[\"choices\"][0][\"text\"]\n",
    "print(title_class)\n",
    "class_prob = exp(r[\"choices\"][0][\"logprobs\"][\"token_logprobs\"][0])\n",
    "print(class_prob)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predicted class is `bad`, which means the probability a `good` class is 1 - given prob (the documentation says you need to return both good and bad probabilites; this is not necessary and increases cost)\n",
    "\n",
    "Now, let's run the ranker for each of the generated titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The absurd AI-generated professional food photography of DALL-E 2',\n",
       "  0.372289056797075),\n",
       " ('<strong>Absurd AI-Generated Professional Food Photography with DALL-E 2</strong>',\n",
       "  0.2928750315951806),\n",
       " ('DALL-E 2: Creating absurd AI-generated professional food photography',\n",
       "  0.5203173838702648),\n",
       " ('DALL-E 2 creates absurd AI-generated professional food photography',\n",
       "  0.5408895391518186),\n",
       " ('A new level of absurdity: AI-generated professional food photography with DALL-E 2',\n",
       "  0.17769626921208903),\n",
       " ('DALL-E 2: The AI that creates absurdly realistic professional food photography',\n",
       "  0.6860428428995713),\n",
       " ('How DALL-E 2 creates absurd AI-generated professional food photography',\n",
       "  0.4876431376731942)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_titles = list(set(gen_titles + [title_input]))  # also dedupes generated titles\n",
    "\n",
    "ranked_titles = []\n",
    "\n",
    "for gen_title in gen_titles:\n",
    "    r = openai.Completion.create(\n",
    "        model=os.getenv(\"FINETUNED_MODEL\"),\n",
    "        prompt=finetune_prompt.format(gen_title),\n",
    "        temperature=0,  # must be 0\n",
    "        max_tokens=1,  # must be 1\n",
    "        logprobs=1,  # returns the probability\n",
    "    )\n",
    "\n",
    "    title_class = r[\"choices\"][0][\"text\"]\n",
    "    class_prob = exp(r[\"choices\"][0][\"logprobs\"][\"token_logprobs\"][0])\n",
    "    if title_class == \" bad\":\n",
    "        class_prob = 1.0 - class_prob\n",
    "\n",
    "    # the <strong> will emphasize the input when we pretty-render it\n",
    "    ranked_titles.append(\n",
    "        (\n",
    "            f\"<strong>{gen_title}</strong>\" if gen_title == title_input else gen_title,\n",
    "            class_prob,\n",
    "        )\n",
    "    )\n",
    "\n",
    "ranked_titles\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can make the results pretty using a [pandas](https://pandas.pydata.org) dataframe!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Title</th>\n",
       "      <th>Good Prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>DALL-E 2: The AI that creates absurdly realistic professional food photography</td>\n",
       "      <td>68.6%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>DALL-E 2 creates absurd AI-generated professional food photography</td>\n",
       "      <td>54.1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>DALL-E 2: Creating absurd AI-generated professional food photography</td>\n",
       "      <td>52.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>How DALL-E 2 creates absurd AI-generated professional food photography</td>\n",
       "      <td>48.8%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>The absurd AI-generated professional food photography of DALL-E 2</td>\n",
       "      <td>37.2%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td><strong>Absurd AI-Generated Professional Food Photography with DALL-E 2</strong></td>\n",
       "      <td>29.3%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>A new level of absurdity: AI-generated professional food photography with DALL-E 2</td>\n",
       "      <td>17.8%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame(ranked_titles, columns=[\"Title\", \"Good Prob\"])\n",
    "df = df.sort_values(by=\"Good Prob\", ascending=False)\n",
    "\n",
    "\n",
    "display(\n",
    "    HTML(\n",
    "        df.to_html(\n",
    "            formatters={\"Good Prob\": lambda x: f\"{x:.1%}\"}, escape=False, index=False\n",
    "        )\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those titles do have a Hacker News appeal."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
